{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChallengeTask Test Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinweise\n",
    "\n",
    "-   **Challenge Modellintegration**:  \n",
    "    In `src/mldog/app/model/challenge_task` finden Sie eine Basisklasse für einen `ChallengeTask`.  \n",
    "    Diese Klasse dient, ähnlich der `Task` Klasse, der Integration Ihres Modells / Ihrer Pipeline in das MLDOG Challenge Framework.  \n",
    "    Im Gegensatz zu der bereits bekannten `Task` Klasse aus MLDOG spezifiziert der `ChallengeTask` eine `predict()`-Methode, die die Daten einer erkannten Bohrung direkt übergeben bekommt und (ausschließlich) das erkannte Material als String zurückgeben soll.  \n",
    "    Implementieren Sie eine neue Challenge Task Klasse für Ihr Team, die von `ChallengeTask` erbt und implementieren Sie die `predict()`-Methode auf Basis Ihres Modells / Ihrer Pipeline.  \n",
    "    Ein Beispiel dazu finden Sie in `src/mldog/app/tasks/example_challenge_task.py`.\n",
    "-   Um Ihren eigenen Challenge Task mit diesem Notebook zu testen, müssen Sie die beiden mit TODO gekennzeichneten Stellen in diesem Notebook entsprechend ergänzen:\n",
    "\n",
    "    1. Import Ihres Challenge Tasks\n",
    "    2. Erzeugung einer Instanz Ihres Challenge Tasks\n",
    "\n",
    "    Abgesehen davon sollten Sie keine Änderungen in diesem Notebook vornehmen müssen (sofern Sie die Beispieldaten aus Moodle in das erwartete Verzeichnis entpackt haben).\n",
    "\n",
    "-   Denken Sie beim Testen daran, dass alle relativen Pfadangaben relativ zu diesem Notebook sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Set Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload external modules (see https://ipython.org/ipython-doc/3/config/extensions/autoreload.html for more information).\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set up system path to include our own \"mldog\" python package.\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# general imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erzeugen der Challenge Task Instanz\n",
    "\n",
    "Importieren Sie hier Ihren eigenen Challenge Task und erzeugen Sie anschließend eine neue Instanz ihres Challenge Tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importieren Sie hier Ihren eigenen Challenge Task\n",
    "from mldog.app.tasks.team_10_challenge_task import Team10ChallengeTask\n",
    "\n",
    "task = Team10ChallengeTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden einer Beispielbohrung\n",
    "\n",
    "Die Daten, die die `predict()`-Methode des Challenge Tasks erhält ist das Ergebnis des `DrillProcedureDetector`s, also ein numpy array mit den Daten einer erkannten Bohrung.\n",
    "\n",
    "Der `DrillProcedureDetector` nutzt die gleichen Parametereinstellungen wie bei der Datenaufzeichnung, also inklusive 0.5 Sekunden vor und nach der eigentlichen Bohrung.\n",
    "\n",
    "Hinweis: Hier wird erwartet, dass Sie die Beispieldaten (aus Moodle) in das übergeordnete `data/raw` Verzeichnis entpackt haben. Sie können hier jedoch auch den Pfad zu einer beliebigen Zeitreihe einer Datenaufzeichnung nutzen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.772461, 19.981535,  0.304667],\n",
       "       [ 1.777344, 19.981535,  0.670878],\n",
       "       [ 1.777344, 19.981535,  0.377909],\n",
       "       ...,\n",
       "       [ 1.75293 , 19.787891,  0.451151],\n",
       "       [ 1.75293 , 19.787891,  0.377909],\n",
       "       [ 1.75293 , 19.787891,  0.451151]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drill_data = np.loadtxt(\n",
    "    \"../data/aufzeichnung_1/2024-10-21_10-00-37/2024_10_21_10_03_49_96000Hz.csv\",\n",
    "    delimiter=\",\",\n",
    ")\n",
    "\n",
    "\n",
    "drill_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausführen des Challenge Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 3/3 [00:01<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: holz-spahn in 3.796875 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# hier wird die run()-Methode des Challenge Tasks aufgerufen, die intern die predict()-Methode aufruft und dabei dessen Laufzeit misst\n",
    "y_pred, runtime = task.run(drill_data)\n",
    "\n",
    "print(f\"Predicted: {y_pred} in {runtime} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldog_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
